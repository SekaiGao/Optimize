{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Optimize\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y(x1,x2)=5*x1^2+2*x2^2+3*x1-10*x2+4\n",
    "def Func(ls):#函数\n",
    "    return 5*ls[0]**2+2*ls[1]**2+3*ls[0]-10*ls[1]+4\n",
    "def Grad(ls):#梯度\n",
    "    g1=10*ls[0]+3\n",
    "    g2=4*ls[1]-10\n",
    "    return np.array([g1,g2])\n",
    "def Hessian(ls):#黑塞矩阵\n",
    "    return np.array([[10,0],[0,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 牛顿法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newton法线性搜索\n",
    "def NTsearch(x0,g,Grad,Hessian):#从x0点开始寻找g方向极小值点\n",
    "    x1=x0.copy()\n",
    "    x2=g#必须也在g方向上\n",
    "    while np.linalg.norm(x2)>1e-3:\n",
    "        x2=(g.dot(Grad(x1)))*g/np.dot(g,np.dot(Hessian(x1),g))\n",
    "        x1-=x2\n",
    "    return x1#返回更新的位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Goldstein线性搜索(非本人实现)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goldstein\n",
    "def GSsearch(Func,Grad,g,x,lr,rho,t):#从x0点出发沿g方向搜索\n",
    "    flag = 0\n",
    "    a = 0\n",
    "    b=lr\n",
    "    fk = Func(x)\n",
    "    gk = Grad(x)\n",
    "    phi0 = fk\n",
    "    dphi0 = np.dot(gk, g)\n",
    "    alpha=b*random.uniform(0,1)\n",
    "    while(flag==0):\n",
    "        newfk = Func(x+alpha*g)\n",
    "        phi = newfk\n",
    "        if (phi - phi0 )<= (rho * alpha * dphi0):\n",
    "            if (phi - phi0) >= ((1 - rho) * alpha * dphi0):\n",
    "                flag = 1\n",
    "            else:\n",
    "                a = alpha\n",
    "                b = b\n",
    "                if (b <lr):\n",
    "                    alpha = (a + b) / 2\n",
    "                else:\n",
    "                    alpha = t * alpha\n",
    "        else:\n",
    "            a = a\n",
    "            b = alpha\n",
    "            alpha = (a + b) / 2\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) Wolfe线性搜索(非本人实现)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wolfe\n",
    "def WFsearch(Func,Grad,g,x,alpham,rho,t):\n",
    "  #σ∈(ρ,1)=0.75\n",
    "  sigma=0.75\n",
    "  flag = 0\n",
    " \n",
    "  a = 0\n",
    "  b = alpham\n",
    "  fk = Func(x)\n",
    "  gk = Grad(x)\n",
    " \n",
    "  phi0 = fk\n",
    "  dphi0 = np.dot(gk, g)\n",
    "  alpha=b*random.uniform(0,1)\n",
    " \n",
    "  while(flag==0):\n",
    "    newfk = Func(x + alpha*g)\n",
    "    phi = newfk\n",
    "    if (phi - phi0 )<= (rho * alpha * dphi0):\n",
    "      # if abs(np.dot(df(x + alpha * d),d))<=-sigma*dphi0:\n",
    "      if (phi - phi0) >= ((1 - rho) * alpha * dphi0):\n",
    "        flag = 1\n",
    "      else:\n",
    "        a = alpha\n",
    "        b = b\n",
    "        if (b < alpham):\n",
    "          alpha = (a + b) / 2\n",
    "        else:\n",
    "          alpha = t * alpha\n",
    "    else:\n",
    "      a = a\n",
    "      b = alpha\n",
    "      alpha = (a + b) / 2\n",
    "  return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最优化方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "def GD(x0,Grad,lr=0.01):\n",
    "\tg=Grad(x0)#梯度\n",
    "\tx1=x0.copy()\n",
    "\twhile np.linalg.norm(g)>1e-4:#梯度范数足够接近0则认为逼近极值点\n",
    "\t\tx1+=-lr*g#x=x-lr*grad\n",
    "\t\tg=Grad(x1)\n",
    "\treturn x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 最速下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steepest descent\n",
    "def SD(x0,Grad,Hessian):\n",
    "\tg=-Grad(x0)\n",
    "\tx1=x0.copy()\n",
    "\twhile np.linalg.norm(g)>1e-4:#解的精度\n",
    "\t\t#NewTon法线性搜索\n",
    "\t\twhile True:\n",
    "\t\t\tlr=(g.dot(Grad(x1)))/np.dot(g,np.dot(Hessian(x1),g))#newton法迭代步长\n",
    "\t\t\tx2=lr*g\n",
    "\t\t\tx1-=x2#梯度下降\n",
    "\t\t\tif np.linalg.norm(x2)<1e-1:#线性搜索精度\n",
    "\t\t\t\tbreak\n",
    "\t\tg=-Grad(x1)\n",
    "\treturn x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 共轭梯度法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conjugate gradient\n",
    "def CG(x0,Grad,Hessian):\n",
    "\td=-Grad(x0)#搜索方向\n",
    "\tg=d\n",
    "\tx1=x0.copy()\n",
    "\twhile np.linalg.norm(g)>1e-4:#解的精度\n",
    "\t\t#NewTon法线性搜索\n",
    "\t\twhile True:\n",
    "\t\t\tlr=(d.dot(Grad(x1)))/np.dot(d,np.dot(Hessian(x1),d))#newton法迭代步长\n",
    "\t\t\tx2=lr*d\n",
    "\t\t\tx1-=x2#梯度下降\n",
    "\t\t\tif np.linalg.norm(x2)<1e-1:#线性搜索精度\n",
    "\t\t\t\tbreak\n",
    "\t\t#Wolfe线性搜索和Goldstein线性搜索\n",
    "\t\t#x1+=WFsearch(Func,Grad,g,x1,1,0.1,2)*g\n",
    "\t\t#x1+=GSsearch(Func,Grad,g,x1,1,0.1,2)*g\n",
    "\t\tg1=-Grad(x1)\n",
    "\t\t#系数b分两种更新方法:FR,PRP\n",
    "\t\t#b=g1.dot(g1)/g.dot(g)#FR\n",
    "\t\tb=(g1-g).dot(g1)/g.dot(g)#PRP\n",
    "\t\td=g1+b*d\n",
    "\t\t'''可加\n",
    "\t\tif d.dot(g1)<0:\n",
    "\t\t\td=g1\n",
    "\t\t'''\n",
    "\t\tg=g1\n",
    "\treturn x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 牛顿法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NewTon\n",
    "def NewTon(x0,Grad,Hessian):\n",
    "    x1=x0.copy()\n",
    "    v=np.ones(len(x0))\n",
    "    while np.linalg.norm(v)>1e-8:\n",
    "        #gaussj消元法求解步长\n",
    "        v=np.linalg.solve(Hessian(x1),-Grad(x1))#Hv=-grad\n",
    "        x1+=v#更新\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 拟牛顿法(未完全完成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BFGS\n",
    "def BFGS(x0,Func,Grad):\n",
    "    B=np.eye(x0.shape[0])\n",
    "    g=Grad(x0)\n",
    "    x1=x0.copy()\n",
    "    while np.linalg.norm(g)>1e-4:\n",
    "        s=-np.linalg.solve(B,g)\n",
    "        #线性搜索\n",
    "        lr=GSsearch(Func,Grad,s,x1,1,0.1,2)\n",
    "        x1+=lr*s\n",
    "        y=-g\n",
    "        g=Grad(x1)\n",
    "        y+=g\n",
    "        B=B+y.T.dot(y)/y.dot(s)-(B.dot(s)).dot(s.dot(B))/s.dot(B.dot(s))\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始点\n",
    "x0=np.array([74.,-49.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "极值点 [-0.3         2.49997587]\n",
      "极值 -8.949999998835054\n"
     ]
    }
   ],
   "source": [
    "z=GD(x0,Grad)\n",
    "print(\"极值点\",z)\n",
    "print(\"极值\",Func(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "极值点 [-0.30000188  2.49998304]\n",
      "极值 -8.949999999407265\n"
     ]
    }
   ],
   "source": [
    "z=SD(x0,Grad,Hessian)\n",
    "print(\"极值点\",z)\n",
    "print(\"极值\",Func(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "极值点 [-0.3  2.5]\n",
      "极值 -8.95\n"
     ]
    }
   ],
   "source": [
    "z=CG(x0,Grad,Hessian)\n",
    "print(\"极值点\",z)\n",
    "print(\"极值\",Func(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "极值点 [-0.3  2.5]\n",
      "极值 -8.950000000000001\n"
     ]
    }
   ],
   "source": [
    "z=NewTon(x0,Grad,Hessian)\n",
    "print(\"极值点\",z)\n",
    "print(\"极值\",Func(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.64 ms ± 296 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit GD(x0,Grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721 µs ± 106 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit SD(x0,Grad,Hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208 µs ± 24.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit CG(x0,Grad,Hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 µs ± 9.07 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit NewTon(x0,Grad,Hessian)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "398c3adbdfadc98f1f32006d2f084d4b125e0f310248e6d55ea96054793fbe2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
